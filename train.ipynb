{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sucheng/anaconda3/envs/imase/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from evaluate import evaluate\n",
    "from unet import UNet\n",
    "from utils.data_loading_copy import BratsDataset\n",
    "from utils.dice_score import dice_loss\n",
    "from os.path import splitext, isfile, join\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.导入数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路径定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = './brain_images'\n",
    "VALIDATION_DATASET_PATH = TRAIN_DATASET_PATH + '/val_brain_images'\n",
    "TEST_DATASET_PATH = TRAIN_DATASET_PATH  + './test_brain_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解压文件(只执行一次)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = tarfile.open('/home/sucheng/Pytorch-UNet/data/BraTS2021_Training_Data.tar')\n",
    "# file.extractall(TRAIN_DATASET_PATH)\n",
    "# file.close()\n",
    "\n",
    "# file = tarfile.open('/home/sucheng/Pytorch-UNet/data/BraTS2021_00621.tar')\n",
    "# file.extractall(VALIDATION_DATASET_PATH)\n",
    "# file.close()\n",
    "\n",
    "# file = tarfile.open('/home/sucheng/Pytorch-UNet/data/BraTS2021_00495.tar')\n",
    "# file.extractall(TEST_DATASET_PATH)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories)\n",
    "\n",
    "\n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2)\n",
    "train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义数据类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BratsDataset(Dataset):\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
    "        # 初始化Initialization\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch '\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = torch.zeros((self.batch_size * VOLUME_SLICES, 2, *self.dim, self.n_channels))  # 使用torch.Tensor代替NumPy数组\n",
    "        y = torch.zeros((self.batch_size * VOLUME_SLICES, 4, IMG_SIZE, IMG_SIZE))  # 只有一个通道的标签图像\n",
    "        Y = torch.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii.gz')\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz')\n",
    "            ce = nib.load(data_path).get_fdata()\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii.gz')\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "\n",
    "            for j in range(VOLUME_SLICES):\n",
    "                X[j+(VOLUME_SLICES*c),:,:,0] = torch.from_numpy(cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)))\n",
    "\n",
    "                X[j+(VOLUME_SLICES*c),:,:,1] = torch.from_numpy(cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)))\n",
    "\n",
    "\n",
    "                y[j +VOLUME_SLICES*c,:,:] = torch.from_numpy(cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)))\n",
    "\n",
    "        # Generate masks(One-Hot encoding)\n",
    "        y[y==4] = 3\n",
    "        y = torch.nn.functional.one_hot(y.to(torch.int64), num_classes=4).permute(0, 3, 1, 2).float()  # 进行One-Hot编码\n",
    "        #Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        #Y = np.array(Y).reshape(1,128,128,128)\n",
    "        return X / X.max(), y  # 返回归一化后的输入图像和One-Hot编码后的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--epochs E] [--batch-size B]\n",
      "                             [--learning-rate LR] [--load LOAD]\n",
      "                             [--scale SCALE] [--validation VAL] [--amp]\n",
      "                             [--bilinear] [--classes CLASSES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"4b1c6b08-c2d9-415d-83ef-f438aad19e2e\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/home/sucheng/.local/share/jupyter/runtime/kernel-v2-425752aVgMWZZfe1ed.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sucheng/anaconda3/envs/imase/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5, help='Downscaling factor of the images')\n",
    "    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
    "    return parser.parse_args()\n",
    "\n",
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "model = UNet(n_channels=3, n_classes=args.classes, bilinear=args.bilinear)\n",
    "model = model.to(memory_format=torch.channels_last)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
